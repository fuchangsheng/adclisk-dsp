总共应该有两个项目，一个为训练模型（输入日志文件，训练参数），一个为预测模型（载入预测模型的参数结果，输入广告网络中的单个用户特征信息，获得预测该用户的点击概率）。

运行相关
---------------------------------------------------------------------------------------------------
需要python3，4Gb以上内存。
make
python3 run.py

训练数据有两千条数据，但运行时长可能需要十分钟左右。
大部分时间用于ffm的模型参数保存IO上，ffm的保存结果有3Gb，但文件大小并不会因训练数据的增多而变大。


训练模型分为两个部分。第一部分为gbdt，用于产生新的特征。第二部分为ffm，用于产生最后的结果。
libffm中采用了随机初始化，所以每次运行的结果都会略有不同。



文件相关
---------------------------------------------------------------------------------------------------
** = ｛te | tr｝te表示测试集相关，tr表示训练集相关

输出文件：
Fc.trva.t10.txt        特征的频率统计结果
**.gbdt.dense          作为gbdt输入的稠密特征部分
**.gbdt.dense          作为gbdt输入的稠密特征部分
**.gbdt.out            gbdt的新创建特征结果
gbdt.model             gbdt的训练模型结果
**.ffm                 ffm的输入
**.out                 ffm的输出，即为最终的预测概率
model                  ffm的输出，ffm模型的参数

程序主要文件
Run.py                              主程序
./utils/count.py                    处理日志文件，获得特征统计结果，输出fc.trva.t10.txt
./converters/parallelizer-a.py      用于多线程的预处理，即将总的文件分割成多个部分，与将分割的文件整合为最终结果。
./converters/pre-a.py               预处理文件格式，将日志文件（tr.csv）进行格式处理，输出**.gbdt.dense与**.gbdt.sparse
./gbdt                              ./solvers/gbdt的编译结果，可执行程序。用于从输入特征中获取新特征，输出**.gbdt.out（新的特征结果），gbdt.model决策树的训练后的模型数据，用于初始化预测模型。
./converters/parallelizer-b.py      同parallelizer-a
./converters/pre-b.py               同pre-a.py，将**.gbdt.out结果处理
./ffm-train                         ./solvers/libffm-1.13的编译结果，可执行程序。输入特征信息，训练ffm的参数，输出model(ffm参数结果)
./ffm-predict                       ./solvers/libffm-1.13的编译结果，可执行程序。输入测试集的特征信息，与model。输出最终的预测结果。

其他文件
frequent_feat                       高频率稀疏特征
tr.tiny.csv                         训练集数据
te.tiny.csv                         测试集数据



其它
----------------------------------------------------------------------------------------------------
程序的gbdt和ffm模块使用openMP进行多核并行计算。文件格式处理模块将源文件分割，利用多进程加速计算。

TODO：
1.除了核心模块的./solvers/libffm-1.13, ./solvers/gbdt无需修改，其他处理文件格式的程序都需根据实际日志格式进行修改。
2.根据统计结果自动生成frequent_feat文件
3.将./solvers/libffm更新为libffm新版本
4.将./solvers/gbdt更新为xgboost新版本
